# Overlapping indices {#sec-overlap}

## Overlap overview

```{r}
#| results: asis
#| echo: false
function_structure("overlap")
```

`overlap` provides a table with some of the most important overlap indices for each case of an *scdf*. For calculating overlap indicators it is important to know if a decrease or an increase of values is expected between phases. By default `overlap` assumes an increase in values. If the argument `decreasing = TRUE` is set, calculation will be based on the assumption of decreasing values.

```{r}
#| warning: false
overlap(exampleAB)
```

Overlap measures refer to a comparison of two phases within a single-case data-set. By default, `overlap` compares the first to the second phase.

### Select and recombine phases {#sec-select-phases}

```{r}
#| results: asis
#| echo: false
function_structure("select_phases")
```

The `select_phases()` function is needed if you like to compare specific phases or even like to combine several phases. `select_phases()` is designed to work within a pipe structure. So the first argument is an *scdf* and it returns an *scdf*.

```{r eval = FALSE}
scdf |> select_phases(A = 1, B = 3) |> ...
```

`select_phases()` has the arguments `A` and `B`. Each argument takes a vector with the names or the numbers of the phases to be selected. If you want to compare the first to the third phase you can set `select_phases(scdf, 1,3)`. If the phases of your case are named 'A', 'B', and 'C' you could alternatively set `select_phases(scdf, "A","C")`. It is also possible to compare a combination of several cases against a combination of other phases. Each of the two list-elements could contain more than one phase which are concatenated with the `c` command. For example if you have an ABAB-Design and like to compare the two A-phases against the two B-phases `select_phases(scdf, c(1,3), c(2,4) )` will do the trick.

(As an alternative approach you can set the `phases` argument within the `overlap()` function. This argument takes a list with two elements where the first element defines the phases for the A-phase and the second argument the phases for the B-phase.)

```{r}
#| warning: false
exampleA1B1A2B2 |>
  select_phases(c("A1","A2"), c("B1","B2")) |>
  overlap()

# Alternatively:
# overlap(exampleA1B1A2B2, phases = list( c("A1","A2"), c("B1","B2")))
```


## Percentage non-overlapping data (PND) {#sec-pnd}

```{r}
#| results: asis
#| echo: false
function_structure("pnd")
```

The percentage of non-overlapping data (PND) effect size measure was described by @scruggs_quantitative_1987 . It is the percentage of all data-points of the second phase of a single-case study exceeding the maximum value of the first phase. In case you have a study where you expect a decrease of values in the second phase, PND is calculated as the percentage of data-point of the second phase below the minimum of the first phase.

```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 3
#| fig-cap: Illustration of PND. PND is 60% as 9 out of 15 datapoints of phase B are higher than the maximum of phase A

random_scdf(design(1, level = 1.0),round = 0, seed = 1212) |>
  scplot() |> 
  add_statline("max", phase = "A", color = "red") |>
  add_text("Maximum of A", x = 1, y = 63, hjust = 0, color = "darkblue", size = 1) |>
  add_marks(positions = "values > max(values[phase == 'A'])", size = 2, shape = 16) |> 
  set_theme("basic")
```

The function `pnd` provides the PND for each case as well as the mean of all PNDs of that *scdf*. When you expect decreasing values set `decreasing = TRUE`. When there are more than two phases or phases are not named A and B, use the `phases` argument as described at the beginning of this chapter.

```{r}
pnd(exampleAB)
```

## Percentage exceeding the median (PEM) {#sec-pem}

```{r}
#| results: asis
#| echo: false
function_structure("pem")
```

The pem function returns the percentage of phase B data exceeding the phase A median. Additionally, a binomial test against a 50/50 distribution is computed. Different measures of central tendency can be addressed for alternative analyses.

```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 3
#| fig-cap: Illustration of PEM. PEM is 75% as 13 out of 15 datapoints of phase B are higher than the median of phase A

random_scdf(design(1, level = 1.0),round = 0, seed = 1212) |>
  scplot() |> add_statline("median", phase = "A", color = "red") |>
  add_text("Median of A", x = 1, y = 54, hjust = 0, color = "darkblue", size = 1) |>
  add_marks(positions = "values > median(values[phase == 'A']) & phase == 'B'", size = 2, shape = 16)|> 
  set_theme("basic")
```

```{r}
pem(exampleAB)
```

## Percentage exceeding the regression trend (PET) {#sec-pet}

```{r}
#| results: asis
#| echo: false
function_structure("pet")
```

The pet function provides the percentage of phase B data points exceeding the prediction based on the phase A trend. A binomial test against a 50/50 distribution is computed. Furthermore, the percentage of phase B data points exceeding the upper (or lower) 95 percent (default) confidence interval of the predicted progress is computed.

```{r}
pet(exampleAB)
```

```{r}
#| echo: false
#| fig-width: 4
#| fig-height: 3
#| fig-cap: Illustration of PET. PET is 66.7% as 10 out of 15 datapoints of phase B are higher than the projected trend-line of phase A

random_scdf(design(1, phase_design = list(A = 10, B = 15), level = 0.4),round = 0, seed = 9871) |> 
  scplot() |> add_statline("trendA", color = "red") |>
  add_text("Trend of A", x = 1, y = 53, hjust = 0, color = "darkblue", size = 1, angle = 6) |>
  add_marks(positions = c(12, 14:19, 21, 22,25), size = 2, shape = 16)|> 
  set_theme("basic")
```

## Percentage of all non-overlapping data (PAND) {#sec-pand}

```{r}
#| results: asis
#| echo: false
function_structure("pand")
```

The `pand` function calculates the percentage of all non-overlapping data [@parker_percentage_2007], an index to quantify a level increase (or decrease) in performance after the onset of an intervention. The authors emphasize that PAND is designed for application in a multiple case design with a substantial number of measurements, technically at least 20 to 25, but preferably 60 or more. PAND is defined as 100% minus the percentage of data points that need to be removed from either phase in order to ensure nonoverlap between the phases.

Several approaches have been suggested to calculate PAND, leading to potentially different outcomes. In their 2007 paper, Parker and colleagues present an algorithm for computing PAND. The algorithm involves sorting the scores of a time series, including the associated phases, and comparing the resulting phase order with the original phase order using a contingency table. To account for ties, the algorithm includes a randomization process where ties are randomly assigned to one of the two phases. Consequently, executing the algorithm multiple times could yield different results. It is important to note that this algorithm does not produce the same results as the PAND definition provided earlier in the same paper. However, it offers the advantage of allowing the calculation of an effect size measure `phi`, and the application of statistical tests for frequency distributions. `phi` equals Pearsons r for dichotomous data. Thus, phi-Square is the amount of explained variance.

@pustejovsky2019 presented a mathematical formulation of Parker's original definition for comparing two phases of a single case:

$$PAND = \frac{1}{m+n}max\{(i+j)I(y^A_{i}<y^B_{n+1-j}\}$$

This formulation provides accurate results for PAND, but the original definition has the drawback of an unknown distribution under the null hypothesis, making a statistical test difficult.

The `pand()` function enables the calculation of PAND using both methods. The first approach (`method = "sort"`) follows the algorithm described above, with the exclusion of randomization before sorting to avoid ambiguity. It calculates a phi measure and provides the results of a chi-squared test and a Fisher exact test. The second approach (`method = "minimum"`) applies the aforementioned formula. For a multiple case design, overlaps are calculated for each case, summed, and then divided by the total number of measurements. No statistical test is conducted for this method.

```{r pand-1}
pand(Parker2007)
```

```{r pand-2}
pand(Parker2007, method = "minimum")
```

The original procedure for computing PAND does not account for ambivalent datapoints (ties). The newer NAP overcomes this problem and has better precision-power [@parker_effect_2011].

## Nonoverlap of all pairs (NAP) {#sec-nap}

```{r}
#| results: asis
#| echo: false
function_structure("nap")
```

The `nap` function calculates the nonoverlap of all pairs [@parker_improved_2009]. NAP summarizes the overlap between all pairs of phase A and phase B data points. Therefore, every single measurement of phase A is compared to all measurements in phase B, resuting in $n_{Phase A} \times n_{Phase B}$ pairs. If an increase in phase B values is expected, a non-overlapping pair will have a higher phase B data point. The NAP is equal to the number of pairs showing no overlap / number of pairs. Since NAP has values between 0 and 100% where 50% is no effect, a rescaled NAP (ranging between -100 and 100%, where 0% is no effect) has been proposed. NAP is equivalent to the U-test and the Wilcoxon rank sum test. Therefore, a Wilcoxon signed rank sum test is conducted and reported for each case. Additionally, effect sizes d and R-squared are reported according to Parker and colleagues.

```{r}
nap(exampleAB)
```

## Improvement rate difference (IRD) {#sec-ird}

```{r}
#| results: asis
#| echo: false
function_structure("ird")
```

The adaptation of the improvement rate difference for single-case phase comparisons was developed by @parker2009. A variation called robust improvement rate difference was proposed by @parker_effect_2011. The `ird()` function calculates the robust improvement rate difference. It follows the formula suggested by @pustejovsky2019. For a multiple case design, IRD is based on the overall improvement rate of all cases which is the average of the IRDs for each case.

```{r}
ird(exampleAB)
```

## Tau-U {#sec-tauu}

```{r}
#| results: asis
#| echo: false
function_structure("tau_u")
```

The *Tau-U* statistic has been proposed by @parker_combining_2011 and is one of the more broadly used approach for reporting effect sizes of single case data. Unfortunately, various and ambiguous implementations of Tau-U exist [@pustejovsky2016; @brossart2018a]. The `tau_u` function tries to cover several of these implementation. It takes an *scdf* and returns Tau-U calculations for each single-case within that file. Additionally, an overall Tau-U value is calculated for all cases based on a meta-analysis.

### Variations of Tau-U

Several arguments can be set to define how Tau-U should be calculated. When setting the argument `method = "parker"`, Tau-U is according to @parker_combining_2011. However, this procedure could lead to Tau-U values above 1 and below -1 which are difficult to interpret. Additionally, this method uses Kendall's Tau A, which does not correct for ties, and no continuity correct is calculated. The default setting `method = "complete"` applies a correction that keeps the values within the -1 to 1 range. `method = "tarlow"` applies a variation that has been implemented by @tarlow2017 . This method is similar to `"complete"` but is based on Tau A rather than Tau B and includes a continuity correction.

Note that the arguments `tau_method` (`"a"` or `"b"`) and `continuity_correction` (`TRUE` or `FALSE`) only function with `method = "complete"`.

My recommendation is to use `method = "complete"` in combination with the defaults `tau_method = "b"` and `continuity_correction = TRUE` for the most appropriate results.

\
Here is an example with setting that reconstruct the values from the original example in @parker2011 :

```{r}
tau_u(Parker2011, method = "parker")
```

A different implementation of the method (provided at [http://www.singlecaseresearch.org/calculators/tau-u)](http://www.singlecaseresearch.org/calculators/tau-u)) uses Kendall's Tau B:

```{r}
tau_u(exampleAB$Johanna, method = "parker", tau_method = "b", continuity_correction = FALSE)
```

Another online calculator created by Rumen Manolov is available at <https://manolov.shinyapps.io/Overlap/>. It uses an R code developed by Kevin Tarlow to calculate Tau-U. This setting will replicate the results of this approach:

```{r}
tau_u(exampleAB$Johanna, method = "tarlow")
```

The standard return of the `tau_u` function does not display all calculations. If you like to have more details, apply the `print` function with the additional argument `complete = TRUE`.

```{r}
tau_u(exampleAB$Johanna) |> print(complete = TRUE)
```

### Meta analyses

::: callout-note
The procedure for calculating the meta-analyses has changed with scan version 0.55.7. Please make sure you are using the latest scan version.
:::

If you pass multiple cases to the `tau-u` function, it will calculate a Tau-U table for each case and an overall calculation via a meta-analysis.

::: callout-note
## Calculating a Tau-U meta analysis

The calculation of the Tau-U-meta-analyses involves the following steps:

1.  The tau values are Fisher-Z transformed to $Tau_z$.

2.  The standard error for each transformed value is calculated as either:

    $se_z = {1 \over \sqrt{n-3}}$ [@hotelling1953]

    or\
    $se_z = \sqrt{0.437 \over n-4}$ [@fieller1957]

3.  The average $tau_z$ is the mean of $tau_z$ weighted by $1 \over se_z^2$

4.  The standard error of the average $tau_z$ is $se_{M_{tau_z}} = \sqrt{\frac{1}{\sum{weights}}}$ [@cooper2009]

5.  The p value is calculated with a Z-test (from $Z = \frac{M_{tau_z}}{se_{M_{tau_z}}}$ )

6.  The overall tau value is derived from an inverse-Fisher-Z-transformation.
:::

### Confidence intervals

::: callout-note
The default method for calculating the confidence interval has changed with scan version 0.55.7. Confidence intervals could have been outside the \[-1, 1\] in earlier versions. Set `ci_method = "s"` for a replication of results from scan version 0.55.6 or earlier.
:::

By default, 95% confidence intervals are calculated for each tau value. You can specify a different interval with the `ci` argument (`ci = 0.90` will calculate a 90% interval). There are three alternative methods for calculating the confidence intervals. When `ci_method = "z"` is set (the default), a general formula for calculating the standard-error of Fisher-Z values is used [@hotelling1953]. If `ci_method = "tau",` a specific formula for Fisher-Z transformed tau values is applied [@fieller1957]. Both approaches give similar results. A third approach is derived from the standard deviation of the S statistic[^ch_overlapping_indices-1]. For this method, set `ci_method = "s"`. The S method can give implausible values less than -1 or greater than 1. I recommend using the general "z" method or the accurate "tau" method.Ã¥

[^ch_overlapping_indices-1]: S is the difference between concordant and discordant comparisons in a Kendall's tau calculation. This is the same statistic used to calculate the p-value.

```{r}
tau_u(exampleAB, ci = 0.90, ci_method = "tau")
```

## Baseline corrected tau {#sec-bctau}

```{r}
#| results: asis
#| echo: false
function_structure("corrected_tau")
```

This method has been proposed by @tarlowImprovedRankCorrelation2016a. The baseline data are checked for a significant autocorrelation (based on Kendalls Tau). If so, a non-parameteric Theil-Sen regression is applied for the baseline data where the dependent values are regressed on the measurement time. The resulting slope information is then used to predict data of the B-phase. The dependent variable is now corrected for this baseline trend and the residuals of the Theil-Sen regression are taken for further calculations. Finally, Kendalls tau is calculated for the dependent variable and the dichotomous phase variable. The function here provides two extensions to this procedure: The alternative Siegel repeated median regression is applied when `repeated = TRUE` [@siegelRobustRegressionUsing1982] and a continuity correction is applied when `continuity = TRUE` (both not the defaults).

Here is a replication of an example provided by @tarlowImprovedRankCorrelation2016a :

```{r}
#| label: bctau-example-plot
#| echo: false
#| message: false

case <- scdf(c(A = 33, 25, 17, 25, 14, 13,14, 
               B = 14, 15, 15, 4, 6, 9, 5 ,4 ,2 ,2 ,8, 11 ,7))

scplot(case) |> 
  add_statline("trendA", method = "theil-sen",  color = "black", linetype = "dotted")  |> 
  add_text("Theil-Sen", x = 9, y = 9)  |> 
  set_ylabel("BDI (Depression)")  |> 
  set_xlabel("Session")  |> 
  set_theme("basic") |> 
  set_casenames("")
```

```{r}
#| label: bctau-example

case <- scdf(
  c(A = 33, 25, 17, 25, 14, 13,14, 
    B = 14, 15, 15, 4, 6, 9, 5 ,4 ,2 ,2 ,8, 11 ,7)
)

corrected_tau(case)
```

## Within case standardized mean differences {#sec-smd}

```{r}
#| results: asis
#| echo: false
function_structure("smd")
```

Standardized mean differences between two phases within a single-case can be calculated in various ways. They refer to the difference in the means of two phases divided by a (within case) standard deviation. The `smd` function provides an overview of the most common parameters for each single-case:

```{r}
smd(exampleAB_score)
```

The first four rows give the mean and the standard deviation of the two respective phases. `sd cohen` is the (unweighted) average of the standard deviation of phase A and B: $\sqrt{\frac{{\text{sdA}^2 + \text{sdB}^2}}{2}}$. `sd Hedges` is the weighted average of the standard deviation with a correction for degrees of freedom: $\sqrt{\frac{ (nA - 1) \cdot \text{sdA}^2 + (nB - 1) \cdot \text{sdB}^2 }{ nA + nB - 2 }}$. `Hedges' g` is the mean difference divided by `sd Hedges`. `Hedges' g correction` ($Hedges' g * (1 - \frac{3}{4n - 9})$) and `Hedges' g durlak correction` ($Hedges' g * (\frac{{n - 3}}{{n - 2.25}} \cdot \sqrt{\frac{{n - 2}}{{n}}})$) are two approaches of correcting Hedges' g for small sample sizes. `Glass' delta` is the mean difference divided by the standard deviation of the A-phase. `Cohen's d` is the mean difference divided by `sd cohen`.

## Between case standardized mean differences {#sec-bcsmd}

```{r}
#| results: asis
#| echo: false
function_structure("between_smd")
```

The previous section described the calculation of standardized mean differences *within* a subject (here: between two phases of one single case). An inherent problem with this calculations is, that the idea and measures of standardized mean differences (e.g. Cohen's *d*) have been developed to characterize the differences between groups. That is, a difference is standardized by the variation *between* subjects in a group. These are two fundamentally different things. Variations *within* a subject might be due to measurement errors or individual fluctuations in the strength of an attribute across time. Whereas the variations *between* subjects indicate a social frame of reference for what is large or small. Accordingly, it is not sensible to apply the well known standards to classify standardizes mean differences (e.g., Cohen's cut-off values for the interpretation of *d*) to within case standardized mean differences. Within case standardized mean differences are usually much larger compared to these cut-offs as variations within a subject across time are (mostly) much smaller that differences between subjects.

@hedges2012 proposed an approach to calculate the between case standardized mean difference, that is conceptually equivalent to Cohen's *d.* This approach is applicable when we have a study with multiple single-cases (here: not just two or three but, depending on the actual data structure, maybe fifteen, or more). The basic idea is, to calculate a multi-level regression model (measurements nested in subjects) with a random intercept (here: between case standard deviation of the intercept) and the *phase* variable as a dummy coded fixed predictor (see @sec-hplm for details on the calculation of multilevel single case regression models).

The estimated regression weight of the phase predictor (here: the mean differences between the phases) is divided by the size of the random intercept (and the residuals) to give the *bcsmd* (between case standardised mean difference).

This basic procedure and some extensions to it are provided with the `between_smd()` function:

```{r}
#| label: bcsmd
between_smd(Leidig2018)
```

The *Base* model provides the *bcsmd* as originally proposed. The *Full plm* model adds trend and slope effects to the regression model for a more precise estimation.

By setting the argument `include_residuals = FALSE`, the residuals are not counted towards the between case standard deviation. This leads two are more precise estimation of the standard deviations but at the cost that the *bcsmd* is conceptually less accurately reflecting Cohen's *d.*:

```{r}
between_smd(Leidig2018, include_residuals = FALSE)
```

The argument `model` allows to define whether the analyses is based on a frequentist or bayesianian regression model.

It is also possible to first calculate a *hierarchichal piecewise regression model* (hplm, see @sec-hplm) and then base the *bcsmd* calculation on that model:

```{r}
hplm(Leidig2018, slope = FALSE) |> between_smd()
```


## Reliable change index {#sec-rci}

```{r}
#| results: asis
#| echo: false
function_structure("rci")
```

Basically, the reliable change index (rci) shows whether a post-test is above a pre-test value. Based on the reliability of the measurements and the standard deviation, the standard error is calculated. The mean difference between phase A and phase B is divided by the standard error. Several authors have proposed refined methods for calculating the rci.

The `rci` function calculates two indices of reliable change [@wise_methods_2004] and corresponding descriptive statistics.

```{r}
rci(exampleAB$Johanna, rel = 0.8)
```


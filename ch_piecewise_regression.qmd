# Piecewise linear regressions {#sec-plm}

```{r}
#| label: setup
#| include: false
library(knitr)
library(kableExtra)
```

In a piecewise-regression analysis (sometimes called segmented regression) a dataset is split at a particular break point and the regression parameters (intercept and slopes) are calculated separately for the data before and after the break point. This is done because we assume that there is a qualitative change at the break point that affects the intercept and slope. This approach is well suited to the analysis of single-case data which are from a statistical point of view time-series data segmented into phases. A general model for single-case data based on the piecewise regression approach has been proposed by Huitema and McKean @huitema_design_2000. They refer to two-phase single-case designs with a pre-intervention phase containing some measurements before the start of the intervention (A-phase) and an intervention phase containing measurements starting at the beginning of the intervention and continuing throughout intervention (B-phase).

In this model, four parameters predict the outcome at a specific measurement point:

1.  The performance at the beginning of the study (**intercept**),

2.  a developmental effect leading to a continuous increase throughout all measurements (**trend effect**),

3.  an intervention effect leading to an immediate and constant increase in performance (**level effect**), and

4.  a second intervention effect that evolves continuously with the beginning of the intervention (**slope effect**).

```{r figure-plm, echo = FALSE, fig.height=4, fig.width=6}
ex <- scdf(c(A = 1,3,3,4,2,3,4,5,4, 4, B = 8,7,8,9,9,7,11,10,10,13))
scplot(ex) %>%
  add_theme("minimal") %>%
  add_statline("trend", color = "red") %>%
  add_statline("trendA", color = "red") %>%
  add_arrow(x0 = 10.5, y0 = 7, x1 = 10.5, y1 = 5, ends = "both", color = "blue3") %>%
  add_arrow(x0 = 1, y0 = 0, x1 = 1, y1 = 1.8, color = "blue3") %>%
  add_arrow(x0 = 14, y0 = 10, x1 = 15, y1 = 9.2, color = "blue3") %>%
  add_arrow(x0 = 7, y0 = 2.2, x1 = 8, y1 = 3.5, color = "blue3") %>%
  add_text("Intercept", x = 1.2, y = 0.5, size = 1.2, hjust = 0, color = "deeppink4") %>%
  add_text("Level effect", x = 10.7, y = 6, color = "deeppink4", size = 1.2, hjust = 0) %>%
  add_text("Slope effect", x = 14, y = 10.2, color = "deeppink4", size = 1.2) %>%
  add_text("Trend effect", x = 7, y = 2, color = "deeppink4", size = 1.2) %>%
  set_casenames(" ") %>%
  set_yaxis(limits = c(0,14))

```

*scan* provides an implementation based on this piecewise-regression approach. Though the original model is extended by several factors:

-   multiple phase designs
-   additional (control) variables
-   autoregression modeling
-   logistic, binomial, and poisson distributed dependent variables and error terms
-   multivariate analyzes for analyzing the effect of an intervention on more than one outcome variable (see @sec-mplm).
-   multilevel analyzes for multiple cases (see @sec-hplm).

## The basic plm function

```{r results='asis', echo=FALSE}
function_structure("plm")
```

The basic function for applying a regression analyzes to a single-case dataset is `plm`. This function analyzes one single-case. In its simplest way, `plm` takes one argument with an *scdf* object and it returns a full piecewise-regression analyzes.

```{r}
#| label: plm-ex-1
plm(exampleAB$Johanna)
```

<!--# describe the output -->

## Adjusting the model

The plm model is a complex model specifically suited for single-case studies. It entails a series of important parameters. Nevertheless, often we have specific theoretical assumption that do no include some of these parameters. We might, for example, only expect an immediate but not a continuous change from a medical intervention. Therefore, it would not be useful to include the slope-effect into our modelling. Vice versa, we could investigate an intervention that will just develop across time without an immediate change with the intervention start. Here we should drop the level-effect from out model. Even the assumption of a trend-effect can be dropped in cases where we do not expect a serial dependency of the data and we do not assume intervention independent changes within the time-frame of the study.

It is important to keep in mind, that an overly complex model might have negative effects on the test power of an analyses (that is, the probability of detecting an actually existing effect is diminished) [see @wilbert2022]

### The `slope`, `level`, and `trend` arguments

<!--# treat each argument separately and add more examples -->

The plm function comes with three arguments (`slope`, `level`, and `trend`) to include or drop the respective predictors from the plm model. Buy default, all arguments are set `TRUE` and a full plm model is applied to the data.

Consider the following data example:

```{r}
example <- scdf(
   values = c(55, 58, 53, 50, 52, 55, 68, 68, 81, 67, 78, 73, 72, 78, 81, 78, 71, 85, 80, 76),
   phase_design = c(A = 5, B = 15)
)

plm(example)
```

The piecewise regression reveals a significant level effect and two non significant effects for trend and slope. In a further analyses we would like to put the slope effect out of the equation. The easiest way to do this is to set the `slope` argument to `FALSE`.

```{r}
plm(example, slope = FALSE)
```

In the resulting estimations the trend and level effects are now significant. The model estimated a trend effect of 1.01 points per measurement time and a level effect of 10.33 points. That is, with the beginning of the intervention (the B-phase) the score increases by 15.38 points (5 x 1.01 + 10.33).

## Adding additional predictors

In more complex analyses, additional predictors can be included in the piecewise regression model.

To do this, we have to change the regression formula 'manually' by applying the `update` argument. The `update` argument allows to change the underlying regression formula. To add a new variable named for example `newVar`, set `update = .~. + newVar`. The `.~.` part takes the internally build model formula (based on the number of phases in your model and the setting of the `slope`, `level`, and `trend` arguments) and `+ newVar` adds a variable called `newVar` to the equation.

Here is an example adding the control variable `cigarrets` to the model:

```{r}
plm(exampleAB_add, update = .~. + cigarrets)
```

The output of the plm-function shows the resulting formula for the regression model that includes the cigarrets variable:\
`Formula: wellbeing ~ day + phaseMedication + interMedication + cigarrets`

```{=html}
<!--#  

completely changing the regression formula:

The formula has two parts divided by a tilde. Left of the tilde is the variable to be predicted and right of it the predictors. A 1 indicates the intercept, the variable mt estimates the trend effect, phaseB the level effect of the B-phase and the variable interB the slope effect of the B-phase (the interaction of measurement-time and phase). If formula is not explicitly defined, it is set to formula = values ~ 1 + mt + phaseB + interB (assuming an AB-design) to estimate the full piecewise regression model.

-->
```
## Dummy models

The `model` argument is used to code the *dummy variables*. These *dummy variables* are used to compute the slope and level effects of the *phase* variable.\
The *phase* variable is categorical, identifying the phase of each measurement. Typically, categorical variables are implemented by means of dummy variables. In a piecewise regression model two phase effects have to be estimated: a level effect and a slope effect. The level effect is implemented quite straight forward: for each phase beginning with the second phase a new dummy variable is created with values of zero for all measurements except the measurements of the phase in focus where values of one are set.

```{r}
#| label: plm-ex-2
#| echo: false
res <- data.frame(
  values = c(3,6,4,7, 5,3,4,6,3), 
  phase = c(rep("A",4),rep("B",5)), 
  mt = 1:9,
  "level B" = c(0,0,0,0,1,1,1,1,1),
  check.names = FALSE
)
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE)
```

For estimating the *slope effect* of each phase, another kind of dummy variables have to be created. Like the dummy variables for level effects the values are set to zero for all measurements except the ones of the phase in focus. Here, values start to increase with every measurement until the end of the phase.\
Various suggestions have been made regarding the way in which these values increase [see @huitema_design_2000]. The *B&L-B* model starts with a one at the first measurement of the phase and increases with every measurement while the *H-M* model starts with a zero.

```{r}
#| echo: false
#| label: dummy-slope

res <- data.frame(
  values = c(3,6,4,7, 5,3,4,6,3), 
  phase = c(rep("A",4),rep("B",5)), 
  mt = 1:9,
  "level B" = c(0,0,0,0,1,1,1,1,1), 
  "model B&L-M" = c(0,0,0,0,1,2,3,4,5), 
  "model H-M" = c(0,0,0,0,0,1,2,3,4), 
  check.names = FALSE )
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c(" " = 4, "slope B" = 2))
```

Applying the *H-M* model will give you a "pure" level-effect while the *B&L-B* model will provide an estimation of the level-effect that is actually the level-effect plus on times the slope-effect (as the the model assumes that the slope variable is *1* at the first measurement of the B-phase). For most studies, the *H-M* model is more appropriate.

Still, we have to be aware of another aspect. Usually, measurement-times in single-case designs are coded as starting with *1* and increasing in integers (e.g., 1, 2, 3, ...). At the same time, the estimation of the trend-effect is based on the measurement-time variable. In that case, the estimation of the model intercept (usually interpreted as the value at the start of the study) actually depicts the estimation of the start value plus one times the trend-effect. Therefore, I implemented the *W* model (since scan version `0.54.4`). Here, the trend-effect is estimated for a measurement-time variable that starts with *0*. As a result the intercept will then represent the estimated value at the first measurement fo the study. The *W* model handles the slope estimation the same way as the *H-M* model. Since scan version `0.54.4` the *W* model is the default.

```{r}
#| echo: false
#| label: dummy-slope-mt

res <- data.frame(
  values = c(3,6,4,7, 5,3,4,6,3), 
  phase = c(rep("A",4),rep("B",5)), 
  level = c(0,0,0,0,1,1,1,1,1),
  "B&L-M and H-M" = 1:9,
  "W" = 0:8,
  "B&L-M" = c(0,0,0,0,1,2,3,4,5), 
  "H-M and W" = c(0,0,0,0,0,1,2,3,4), 
  check.names = FALSE )
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c(" " = 3, "mt" = 2, "slope" = 2))
```

## Designs with more than two phases: Setting the right contrasts

With single-case studies with more than two phases it gets a bit more complicated. Applying the models described above to three phases would result in a comparison between each phase and the first phase (usually phase A). That is, the regression weights and significance tests indicate the differences between each phase and the phase A values. Another common use is to compare the effects of one phase with the preceding phase.

<!--# correct for new arguments contrast_level and contrast_slope -->

\
Since scan version `0.54.4` plm allows to set a contrast argument. `contrast = "first"`\` (the default) will compare all slope and level-effects to the values in the first phase. `contrast = "preceding"`\` will compare the slope and level-effects to the preceding phase. (Note: Prior to scan version `0.54.4` you had to set `model = "JW"` which is identical to `model = "B&L-B", contrast = "preceding"`\`).

For the *preceding contrast*, the dummy variable for the level-effect is set to zero for all phases preceding the phase in focus and set to one for all remaining measurements. Similar, the dummy variable for the slope-effect is set to zero for all phases preceding the one in focus and starts with one for the first measurement of the target phase and increases until the last measurement of the case.

```{r}
#| echo: false
#| label: dummy-contrast

res <- data.frame(
  values =  c(3,6,4,7, 5,3,4,6,3, 7,5,6,4,8), 
  phase = c(rep("A", 4), rep("B", 5), rep("C", 5)), 
  mt = 1:14,
  B = c(0,0,0,0, 1,1,1,1,1, 0,0,0,0,0), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,1,1,1,1), 
  B = c(0,0,0,0, 1,2,3,4,5, 0,0,0,0,0), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,2,3,4,5),
  
  B = c(0,0,0,0, 1,1,1,1,1, 1,1,1,1,1), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,1,1,1,1), 
  B = c(0,0,0,0, 1,2,3,4,5, 6,7,8,9,10), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,2,3,4,5),
  check.names = FALSE)
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c(" " = 3, "level" = 2, "slope" = 2,"level" = 2, "slope" = 2)) %>%
  add_header_above(c(" " = 3, "contrast\nfirst" = 4, "contrast\npreceeding" = 4))
```

## Understanding and interpreting contrasts

In this section, we will calculate four plm models with different contrast settings for the same single-case data.

The example scdf is the case 'Marie' from the *exampleABC* scdf (`exampleABC$Marie`)

```{r}
#| echo: false
#| label: fig-marie
#| fig-cap: Example dataset

scplot(exampleABC$Marie) %>% 
  add_statline("trend", color = "darkred")
  
```

The darkred lines indicate the intercept and slopes when calculated separately for each phase. They are:

```{r}
#| echo: false
#| label: tbl-contrasts-ex-2
#| tbl-cap: Intercept, slope, and number of measurements calculated separately for each phase
res <- trend(exampleABC$Marie)$trend[2:4, 1:2] %>% round(3)
res$n <- 10
row.names(res) <- paste0("phase ", c("A","B", "C"))
colnames(res) <- c("intercept", "slope", "n")
kable(res, align = "c") %>%
  kable_classic(full_width = TRUE)
```

Now we estimate a plm model with four contrast settings:

```{r}
#| echo: false
#| label: tbl-contrast-first-preceding
#| tbl-cap: Estimates of a piecewise-linear regression with contrast models "first" and "preceding".
df <- rbind(
  coef(plm(exampleABC$Marie, contrast_level = "first", contrast_slope = "first"))[,"Estimate"],
  coef(plm(exampleABC$Marie, contrast_level = "preceding", contrast_slope = "preceding"))[,"Estimate"],
  coef(plm(exampleABC$Marie, contrast_level = "first", contrast_slope = "preceding"))[,"Estimate"],
  coef(plm(exampleABC$Marie, contrast_level = "preceding", contrast_slope = "first"))[,"Estimate"]
) %>% 
  round(3) %>% as.data.frame()
names(df) <- c("intercept", "trend", "level B", "level C", "slope B", "slope C")
data.frame(
  "Contrast level" = c("first", "preceding", "first", "preceding"), 
  "Contrast slope" = c("first", "preceding", "preceding", "first"),
  df, 
  check.names = FALSE) %>%
  kable(align = "c") %>%
  kable_classic(full_width = FALSE)
```

### Phase B estimates

All regression models in @tbl-contrast-first-preceding have the same estimates for `intercept` and `trend`. These are not affected by the contrasts and are identical to those for phase A in @tbl-contrasts-ex-2. In addition, in @tbl-contrast-first-preceding, the estimates for `levelB` and `slopeC` are identical since all models contrast the same phase (the first and the preceding phase are both phase A). The values here can be calculated from @tbl-contrasts-ex-2[^ch_piecewise_regression-1]:

[^ch_piecewise_regression-1]: Differences here and in the following calculations are due to rounding errors.

$$
levelB = intercept_{phaseB} - (intercept_{phaseA} + n_{PhaseA} * slope_{phaseA})
$$ {#eq-contrast-level-2}

$$
33.388 \approx  74.855 - (60.618 + 10*-1.915)
$$

$$
slopeB = slope_{phaseB} - slope_{phaseA}
$$ {#eq-contrast-slope-2}

$$
1.303 \approx -1.915 - (-0.612) 
$$

### Phase C estimates

The `levelC` and `slopeC` estimates of the regression models in @tbl-contrast-first-preceding are different for the various contrast models. Depending on the contrast setting, the estimates "answer" a different question. @tbl-interpretation-contrasts provides interpretation help.

| Contrast level | Contrast slope | Interpretation of level C effect                                                                                                                                                                                          | Interpretation slope C effect                                                           |
|------------------|------------------|------------------|------------------|
| first          | first          | What would be the value if phase A had continued until to the start of phase C and what is the difference to the actual value at the first measurement of phase C?                                                        | What is the difference between the slopes of phase C and A[^ch_piecewise_regression-2]? |
| preceding      | preceding      | What would be the value if phase B had continued to the start of phase C and what is the difference to the actual value at the first measurement of phase C?                                                              | What is the difference between the slopes of phase C and B?                             |
| first          | preceding      | What would be the value if phase A had continued until the start of phase C (assuming a slope effect but no level effect in phase B)? And what is the difference to the actual value at the first measurement of phase C? | What is the difference between the slopes of phase C and B?                             |
| preceding      | first          | What would be the value if phase B had continued until the start of phase C (assuming a level but no slope effect in phase B)? And what is the difference to the actual value at the first measurement of phase C?        | What is the difference between the slopes of phase C and A?                             |

: Interpretations of the effect estimates in various contrast conditions {#tbl-interpretation-contrasts}

[^ch_piecewise_regression-2]: The slope of phase A is the trend effect.

All four models are mathematically equivalent, i.e. they produce the same estimates of the dependent variable. Bellow I will show how the estimates from the piecewise regression models relate to the simple regression estimates from @tbl-contrasts-ex-2. These are $intercept_{phaseC} = 68.873$ and $slope_{phaseC} = -0.194$.

***Level first and slope first contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 46.558 compared to phase A (the intercept) and a `slopeC` increase of 1.721.

$$
levelC = intercept_{phaseC} - (Intercept_{phaseA} + n_{phaseA+B} * slope_{phaseA})
$$ {#eq-contrast-ff-1}

$$46.558 \approx 68.873 - (60.618 + 20*-1.915) $$

$$
slopeC = slope_{phaseC} - slope_{phaseA} 
$$ {#eq-contrast-ff-2}

$$1.721 \approx -0.194 - (-1.915)$$

***Level preceding and slope preceding contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 0.139 compared to phase B and a `slopeC` increase of 0.418.

$$
levelC = intercept_{phaseC} - (intercept_{phaseB} + n_{phaseB} * slope_{phaseB})
$$ {#eq-contrast-pp-1}

$$0.139 \approx 68.873 - (74.855 + 10*-0.612)$$

$$
slopeC = slope_{phaseC} - slope_{phaseB}
$$ {#eq-contrast-pp-2}

$$0.418 \approx -0.194 - (-0.612)$$

***Level first and slope preceding contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 33.388 compared to phase A and a `slopeC` increase of 0.418.

$$
levelC = intercept_{phaseC} - (intercept_{phaseA}  + n_{phaseA} * slope_{phaseA} + n_{phaseB} * slope_{phaseB})
$$ {#eq-contrast-fp-1}

$$
33.527 \approx 68.873 - (60.618 + 10 * -1.915 + 10 * -0.612)
$$

$$
slopeC = slope_{phaseC} - slope_{phaseB}
$$ {#eq-contrast-fp-2}

$$0.418 \approx -0.194 - (-0.612)$$

***Level preceding and slope first contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 13.170 compared to phase B and a `slopeC` increase of 1.721.

$$
levelC = intercept_{phaseC} - (intercept_{phaseB} + n_{phaseB} * slope_{phaseA})
$$ {#eq-contrast-pf-1}

$$
13.170\approx 68.873 - (74.855 + 10*-1.915)
$$

$$
slopeC = slope_{phaseC} - slope_{phaseA}
$$ {#eq-contrast-pf-2}

$$
1.721 \approx -0.194 - (-1.915)
$$
<!--# same analyses for models without level estimators and models without slope estimators -->

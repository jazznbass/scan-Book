# Piecewise linear regressions {#sec-plm}

```{r}
#| label: setup
#| include: false
library(knitr)
library(kableExtra)
```

In a piecewise-regression analysis (sometimes called segmented regression) a dataset is split at a particular break point and the regression parameters (intercept and slopes) are calculated separately for the data before and after the break point. This is done because we assume that there is a qualitative change at the break point that affects the intercept and slope. This approach is well suited to the analysis of single-case data which are from a statistical point of view time-series data segmented into phases. A general model for single-case data based on the piecewise-regression approach has been proposed by Huitema and McKean @huitema_design_2000. They refer to two-phase single-case designs with a pre-intervention phase containing some measurements before the start of the intervention (A-phase) and an intervention phase containing measurements starting at the beginning of the intervention and continuing throughout intervention (B-phase).

In this model, four parameters predict the outcome at a specific measurement point [see @fig-plm]

1.  The performance at the beginning of the study (**intercept**),

2.  a developmental effect leading to a continuous increase throughout all measurements (**trend effect**),

3.  an intervention effect leading to an immediate and constant increase in performance (**level effect**), and

4.  a second intervention effect that evolves continuously with the beginning of the intervention (**slope effect**).

```{r echo = FALSE, fig.height=4, fig.width=6}
#| label: fig-plm
#| fig-cap: Illustration of the piecewise-linear model

ex <- scdf(c(A = 1,3,3,4,2,3,4,5,4, 4, B = 8,7,8,9,9,7,11,10,10,13))
scplot(ex) %>%
  set_theme("minimal") %>%
  add_statline("trend", color = "red") %>%
  add_statline("trendA", color = "steelblue3") %>%
  add_arrow(x0 = 10.5, y0 = 7, x1 = 10.5, y1 = 5, ends = "both", color = "blue3") %>%
  add_arrow(x0 = 1, y0 = 0, x1 = 1, y1 = 1.8, color = "blue3") %>%
  add_arrow(x0 = 14, y0 = 10, x1 = 15, y1 = 9.2, color = "blue3") %>%
  add_arrow(x0 = 7, y0 = 2.2, x1 = 8, y1 = 3.5, color = "blue3") %>%
  add_text("Intercept", x = 1.2, y = 0.5, size = 1.2, hjust = 0, color = "deeppink4") %>%
  add_text("Level effect", x = 10.7, y = 6, color = "deeppink4", size = 1.2, hjust = 0) %>%
  add_text("Slope effect\n(difference between red and blue line)", x = 16, y = 11.2, color = "deeppink4", size = 1.2, hjust = 1) %>%
  add_text("Trend effect", x = 7, y = 2, color = "deeppink4", size = 1.2) %>%
  set_casenames(" ") %>%
  set_yaxis(limits = c(0,14))

```

*scan* provides an implementation based on this piecewise-regression approach. Though the original model is extended by several factors:

-   multiple-phase designs,
-   additional (control) variables,
-   autoregression modelling,
-   logistic, binomial, and poisson distributed dependent variables and error terms,
-   multivariate analyses to analyse the effect of an intervention on more than one outcome variable (see @sec-mplm),
-   multilevel analyses for multiple cases (see @sec-hplm).

## The basic plm function

```{r results='asis', echo=FALSE}
function_structure("plm")
```

The basic function for applying a regression analysis to a single-case dataset is `plm`. This function analyses one single-case. In its simplest form, `plm` takes an argument with an *scdf* object and it returns a full piecewise-regression analysis.

```{r}
#| label: plm-ex-1
plm(exampleAB$Johanna)
```

<!--# describe the output -->

## Adjusting the model

The plm model is a complex model specifically suited to single case studies. It includes a number of important parameters. However, we often have specific theoretical assumptions that do not include some of these parameters. For example, we may only expect an immediate change from a medical intervention, not a continuous change. Therefore, it would not be useful to include the slope effect in our modelling. Conversely, we might be looking at an intervention that develops over time, with no immediate change at the start of the intervention. Here we should remove the slope effect from our model. The assumption of a trend effect can also be dropped if we do not expect serial dependence of the data and do not expect intervention-independent changes within the study timeframe.

It is important to bear in mind that an overly complex model may have a negative impact on the power of an analysis (i.e. the likelihood of detecting a true effect is reduced) [see @wilbert2022].

### The `slope`, `level`, and `trend` arguments

<!--# treat each argument separately and add more examples -->

The plm function takes three arguments (`slope`, `level` and `trend`) to include or exclude the respective predictors from the plm model. By default, all arguments are set to `TRUE` and a full plm model is applied to the data.

Consider the following data example:

```{r}
example <- scdf(
   values = c(A = 55, 58, 53, 50, 52, 
              B = 55, 68, 68, 81, 67, 78, 73, 72, 78, 81, 78, 71, 85, 80, 76)
)

plm(example)
```

The piecewise-regression reveals a significant level effect and two non significant effects for trend and slope. In a further analyses we want to remove the slope effect from the equation. The easiest way to do this is to set the `slope` argument to `FALSE`.

```{r}
plm(example, slope = FALSE)
```

In the resulting estimates, the trend and level effects are now significant. The model estimates a trend effect of 1.01 points per measurement time and a level effect of 10.33 points. This means that with the start of the intervention (the B phase), the score increases by 15.38 points (5 x 1.01 + 10.33).

## Adding additional predictors

For more complex analyses, additional predictors can be included in the piecewise regression model.

To do this, we need to modify the regression formula by using the `update` argument. The `update` argument allows the underlying regression formula to be changed. For example, to add a new variable named `newVar`, set `update = .~. + newVar`. The `.~.` part takes the internally built model formula (based on the number of phases in your model and the setting of the `slope`, `level` and `trend` arguments) and `+ newVar` adds a variable named `newVar` to the equation.

Here is an example of adding the control variable `cigarrets` to the model:

```{r}
plm(exampleAB_add, update = .~. + cigarrets)
```

The output of the plm function shows the resulting formula for the regression model that includes the cigarrettes variable:

`Formula: wellbeing ~ day + phaseMedication + interMedication + cigarrets`

```{=html}
<!--#  

completely changing the regression formula:

The formula has two parts divided by a tilde. Left of the tilde is the variable to be predicted and right of it the predictors. A 1 indicates the intercept, the variable mt estimates the trend effect, phaseB the level effect of the B-phase and the variable interB the slope effect of the B-phase (the interaction of measurement-time and phase). If formula is not explicitly defined, it is set to formula = values ~ 1 + mt + phaseB + interB (assuming an AB-design) to estimate the full piecewise regression model.

-->
```
## Dummy models

The `model` argument is used to code the *dummy variables*. These *dummy variables* are used to calculate the slope and level effects of the *phase* variable.\
The *phase* variable is categorical, identifying the phase of each measurement. Typically, categorical variables are implemented using dummy variables. In a piecewise regression model, two phase effects need to be estimated: a level effect and a slope effect. The level effect is implemented quite straightforwardly: for each phase, starting from the second phase, a new dummy variable is created with values of zero for all measurements except the measurements of the phase in focus, where values of one are set.

```{r}
#| label: plm-ex-2
#| echo: false
res <- data.frame(
  values = c(3,6,4,7, 5,3,4,6,3), 
  phase = c(rep("A",4),rep("B",5)), 
  mt = 1:9,
  "level B" = c(0,0,0,0,1,1,1,1,1),
  check.names = FALSE
)
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE)
```

To estimate the *slope effect* of each phase, a different type of dummy variable must be created. Similar to the dummy variables used for level effects, these values are set to zero for all measurements except those taken during the relevant phase. Then, the values gradually increase with each measurement until the end of the phase.

Different methods have been proposed for increasing these values [see @huitema_design_2000]. The *B&L-B* model begins with a value of one at the first measurement of the phase and increases with each subsequent measurement, while the *H-M* model starts with a value of zero.

```{r}
#| echo: false
#| label: dummy-slope

res <- data.frame(
  values = c(3,6,4,7, 5,3,4,6,3), 
  phase = c(rep("A",4),rep("B",5)), 
  mt = 1:9,
  "level B" = c(0,0,0,0,1,1,1,1,1), 
  "model B&L-M" = c(0,0,0,0,1,2,3,4,5), 
  "model H-M" = c(0,0,0,0,0,1,2,3,4), 
  check.names = FALSE )
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c(" " = 4, "slope B" = 2))
```

The *H-M* model yields a "pure" level-effect, while the *B&L-B* model estimates the level-effect plus one times the slope-effect (since the model assumes a value of one for the slope variable at the first measurement of the B-phase). For most studies, the *H-M* model is more appropriate.

However, there is another aspect to consider. In single-case designs, measurement times are usually coded as starting with 1 and increasing in integers (e.g., 1, 2, 3, ...). The trend-effect estimation is based on the measurement-time variable. In this case, the model intercept estimation (typically interpreted as the value at the start of the study) represents the estimated start value plus one times the trend-effect. To address this issue, I implemented the *W* model (since scan version `0.54.4`), which estimates the trend-effect for a measurement-time variable that starts with 0. As a result, the intercept represents the estimated value at the first measurement of the study. The *W* model handles slope estimation in the same way as the *H-M* model. Since scan version `0.54.4`, the *W* model is the default.

```{r}
#| echo: false
#| label: dummy-slope-mt

res <- data.frame(
  values = c(3,6,4,7, 5,3,4,6,3), 
  phase = c(rep("A",4),rep("B",5)), 
  level = c(0,0,0,0,1,1,1,1,1),
  "B&L-M and H-M" = 1:9,
  "W" = 0:8,
  "B&L-M" = c(0,0,0,0,1,2,3,4,5), 
  "H-M and W" = c(0,0,0,0,0,1,2,3,4), 
  check.names = FALSE )
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c(" " = 3, "mt" = 2, "slope" = 2))
```

## Designs with more than two phases: Setting the right contrasts

Single-case studies with more than two phases require a more complex analysis. If we apply the models described earlier to three phases, we would get a comparison between each phase and the first phase (usually phase A). This comparison indicates the differences between each phase and the phase A values. Another common use is to compare the effects of one phase with the preceding phase.

Since scan version `0.54.4`, plm allows to set a contrast argument. By default, `contrast = "first"` will compare all slope and level-effects to the values in the first phase. On the other hand, `contrast = "preceding"` will compare the slope and level-effects to the preceding phase.

For the *preceding contrast*, the dummy variable for the level-effect is set to zero for all phases preceding the phase in focus and set to one for all remaining measurements. Similarly, the dummy variable for the slope-effect is set to zero for all phases preceding the one in focus and starts with one for the first measurement of the target phase and increases until the last measurement of the case.

You can set the contrast differently for the level and slope effects with the arguments `constrast_level` and `contrast_slope`. Both can be either `"first"` or `"preceding"`.

(Note: Prior to scan version `0.54.4`, the option `model = "JW"` was identical to `model = "B&L-B", contrast = "preceding"`).

```{r}
#| echo: false
#| label: dummy-contrast

res <- data.frame(
  values =  c(3,6,4,7, 5,3,4,6,3, 7,5,6,4,8), 
  phase = c(rep("A", 4), rep("B", 5), rep("C", 5)), 
  mt = 1:14,
  B = c(0,0,0,0, 1,1,1,1,1, 0,0,0,0,0), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,1,1,1,1), 
  B = c(0,0,0,0, 1,2,3,4,5, 0,0,0,0,0), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,2,3,4,5),
  
  B = c(0,0,0,0, 1,1,1,1,1, 1,1,1,1,1), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,1,1,1,1), 
  B = c(0,0,0,0, 1,2,3,4,5, 6,7,8,9,10), 
  C = c(0,0,0,0, 0,0,0,0,0, 1,2,3,4,5),
  check.names = FALSE)
kable(res, align = "c") %>%
  kable_classic(full_width = FALSE) %>%
  add_header_above(c(" "=3, "level"=2, "slope"=2, "level"=2, "slope"=2)) %>%
  add_header_above(c(" "=3, "contrast\nfirst"=4, "contrast\npreceeding"=4))
```

## Understanding and interpreting contrasts

In this section, we will calculate four `plm` models with different contrast settings for the same single-case data.

The example data is taken from the `exampleABC` scdf, and we will use the case 'Marie' (`exampleABC$Marie`) for analysis.

```{r}
#| echo: false
#| label: fig-marie
#| fig-cap: Example dataset

scplot(exampleABC$Marie) %>% 
  add_statline("trend", color = "darkred")
  
```

The dark-red lines indicate the intercept and slopes when calculated separately for each phase. They are:

```{r}
#| echo: false
#| label: tbl-contrasts-ex-2
#| tbl-cap: Intercept, slope, and number of measurements calculated separately for each phase
res <- trend(exampleABC$Marie)$trend[2:4, 1:2] %>% round(3)
res$n <- 10
row.names(res) <- paste0("phase ", c("A","B", "C"))
colnames(res) <- c("intercept", "slope", "n")
kable(res, align = "c") %>%
  kable_classic(full_width = TRUE)
```

Now we estimate a plm model with four contrast settings:

```{r}
#| echo: false
#| label: tbl-contrast-first-preceding
#| tbl-cap: Estimates of a piecewise-linear regression with contrast models "first" and "preceding".
df <- rbind(
  coef(plm(exampleABC$Marie, contrast_level = "first", contrast_slope = "first"))[,"Estimate"],
  coef(plm(exampleABC$Marie, contrast_level = "preceding", contrast_slope = "preceding"))[,"Estimate"],
  coef(plm(exampleABC$Marie, contrast_level = "first", contrast_slope = "preceding"))[,"Estimate"],
  coef(plm(exampleABC$Marie, contrast_level = "preceding", contrast_slope = "first"))[,"Estimate"]
) %>% 
  round(3) %>% as.data.frame()
names(df) <- c("intercept", "trend", "level B", "level C", "slope B", "slope C")
data.frame(
  "Contrast level" = c("first", "preceding", "first", "preceding"), 
  "Contrast slope" = c("first", "preceding", "preceding", "first"),
  df, 
  check.names = FALSE) %>%
  kable(align = "c") %>%
  kable_classic(full_width = FALSE)
```

### Phase B estimates

All regression models in @tbl-contrast-first-preceding have the same estimates for `intercept` and `trend`. These are not affected by the contrasts and are identical to those for phase A in @tbl-contrasts-ex-2. In addition, in @tbl-contrast-first-preceding, the estimates for `levelB` and `slopeC` are identical since all models contrast the same phase (the first and the preceding phase are both phase A). The values here can be calculated from @tbl-contrasts-ex-2[^ch_piecewise_regression-1]:

[^ch_piecewise_regression-1]: Differences here and in the following calculations are due to rounding errors.

$$
levelB = intercept_{phaseB} - (intercept_{phaseA} + n_{PhaseA} * slope_{phaseA})
$$ {#eq-contrast-level-2}

$$
33.388 \approx  74.855 - (60.618 + 10*-1.915)
$$

$$
slopeB = slope_{phaseB} - slope_{phaseA}
$$ {#eq-contrast-slope-2}

$$
1.303 \approx -1.915 - (-0.612) 
$$

### Phase C estimates

The `levelC` and `slopeC` estimates of the regression models in @tbl-contrast-first-preceding are different for the various contrast models. Depending on the contrast setting, the estimates "answer" a different question. @tbl-interpretation-contrasts provides interpretation help.

| Contrast level | Contrast slope | Interpretation of level C effect                                                                                                                                                                                          | Interpretation slope C effect                                                           |
|----------------|----------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|
| first          | first          | What would be the value if phase A had continued until to the start of phase C and what is the difference to the actual value at the first measurement of phase C?                                                        | What is the difference between the slopes of phase C and A[^ch_piecewise_regression-2]? |
| preceding      | preceding      | What would be the value if phase B had continued to the start of phase C and what is the difference to the actual value at the first measurement of phase C?                                                              | What is the difference between the slopes of phase C and B?                             |
| first          | preceding      | What would be the value if phase A had continued until the start of phase C (assuming a slope effect but no level effect in phase B)? And what is the difference to the actual value at the first measurement of phase C? | What is the difference between the slopes of phase C and B?                             |
| preceding      | first          | What would be the value if phase B had continued until the start of phase C (assuming a level but no slope effect in phase B)? And what is the difference to the actual value at the first measurement of phase C?        | What is the difference between the slopes of phase C and A?                             |

: Interpretations of the effect estimates in various contrast conditions {#tbl-interpretation-contrasts}

[^ch_piecewise_regression-2]: The slope of phase A is the trend effect.

All four models are mathematically equivalent, i.e. they produce the same estimates of the dependent variable. Bellow I will show how the estimates from the piecewise regression models relate to the simple regression estimates from @tbl-contrasts-ex-2. These are $intercept_{phaseC} = 68.873$ and $slope_{phaseC} = -0.194$.

***Level first and slope first contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 46.558 compared to phase A (the intercept) and a `slopeC` increase of 1.721.

$$
levelC = intercept_{phaseC} - (Intercept_{phaseA} + n_{phaseA+B} * slope_{phaseA})
$$ {#eq-contrast-ff-1}

$$46.558 \approx 68.873 - (60.618 + 20*-1.915) $$

$$
slopeC = slope_{phaseC} - slope_{phaseA} 
$$ {#eq-contrast-ff-2}

$$1.721 \approx -0.194 - (-1.915)$$

***Level preceding and slope preceding contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 0.139 compared to phase B and a `slopeC` increase of 0.418.

$$
levelC = intercept_{phaseC} - (intercept_{phaseB} + n_{phaseB} * slope_{phaseB})
$$ {#eq-contrast-pp-1}

$$0.139 \approx 68.873 - (74.855 + 10*-0.612)$$

$$
slopeC = slope_{phaseC} - slope_{phaseB}
$$ {#eq-contrast-pp-2}

$$0.418 \approx -0.194 - (-0.612)$$

***Level first and slope preceding contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 33.388 compared to phase A and a `slopeC` increase of 0.418.

$$
levelC = intercept_{phaseC} - (intercept_{phaseA}  + n_{phaseA} * slope_{phaseA} + n_{phaseB} * slope_{phaseB})
$$ {#eq-contrast-fp-1}

$$
33.527 \approx 68.873 - (60.618 + 10 * -1.915 + 10 * -0.612)
$$

$$
slopeC = slope_{phaseC} - slope_{phaseB}
$$ {#eq-contrast-fp-2}

$$0.418 \approx -0.194 - (-0.612)$$

***Level preceding and slope first contrasts***

@tbl-contrast-first-preceding estimates a `levelC` increase of 13.170 compared to phase B and a `slopeC` increase of 1.721.

$$
levelC = intercept_{phaseC} - (intercept_{phaseB} + n_{phaseB} * slope_{phaseA})
$$ {#eq-contrast-pf-1}

$$
13.170\approx 68.873 - (74.855 + 10*-1.915)
$$

$$
slopeC = slope_{phaseC} - slope_{phaseA}
$$ {#eq-contrast-pf-2}

$$
1.721 \approx -0.194 - (-1.915)
$$ <!--# same analyses for models without level estimators and models without slope estimators -->
